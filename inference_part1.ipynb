{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import time\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './demo'\n",
    "video_path = os.path.join(root_path,'basketball_01.mp4')\n",
    "file_name = video_path[:-4].split('/')[-1]\n",
    "# save all frames\n",
    "\n",
    "# Opens the Video file\n",
    "raw_path = os.path.join(root_path,file_name)\n",
    "! mkdir -p $raw_path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "i=0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    cv2.imwrite(raw_path + '/' + str(i).zfill(5) + '.jpg',frame)\n",
    "    i+=1\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from distutils.version import LooseVersion\n",
    "# Numerical libs\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.io import loadmat\n",
    "import csv\n",
    "# Our libs\n",
    "from mit_semseg.dataset import TestDataset\n",
    "from mit_semseg.models import ModelBuilder, SegmentationModule\n",
    "from mit_semseg.utils import colorEncode, find_recursive, setup_logger\n",
    "from mit_semseg.lib.nn import user_scattered_collate, async_copy_to\n",
    "from mit_semseg.lib.utils import as_numpy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from mit_semseg.config import cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = loadmat('./semantic-segmentation-pytorch/data/color150.mat')['colors']\n",
    "names = {}\n",
    "with open('./semantic-segmentation-pytorch/data/object150_info.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        names[int(row[0])] = row[5].split(\";\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(segmentation_module, loader, gpu):\n",
    "    segmentation_module.eval()\n",
    "\n",
    "    pbar = tqdm(total=len(loader))\n",
    "    for batch_data in loader:\n",
    "        # process data\n",
    "        batch_data = batch_data[0]\n",
    "        segSize = (batch_data['img_ori'].shape[0],\n",
    "                   batch_data['img_ori'].shape[1])\n",
    "        img_resized_list = batch_data['img_data']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            scores = torch.zeros(1, cfg.DATASET.num_class, segSize[0], segSize[1])\n",
    "            scores = async_copy_to(scores, gpu)\n",
    "\n",
    "            for img in img_resized_list:\n",
    "                feed_dict = batch_data.copy()\n",
    "                feed_dict['img_data'] = img\n",
    "                del feed_dict['img_ori']\n",
    "                del feed_dict['info']\n",
    "                feed_dict = async_copy_to(feed_dict, gpu)\n",
    "\n",
    "                # forward pass\n",
    "                pred_tmp = segmentation_module(feed_dict, segSize=segSize)\n",
    "                scores = scores + pred_tmp / len(cfg.DATASET.imgSizes)\n",
    "           # torch.save(scores,'scores.pt')\n",
    "            _, pred = torch.max(scores, dim=1)\n",
    "            pred = as_numpy(pred.squeeze(0).cpu())\n",
    "\n",
    "        # visualization\n",
    "        visualize_result(\n",
    "            (batch_data['img_ori'], batch_data['info']),\n",
    "            pred,\n",
    "            cfg,scores\n",
    "        )\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_result(data, pred, cfg, scores):\n",
    "    (img, info) = data\n",
    "    # print predictions in descending order\n",
    "    pred = np.int32(pred)\n",
    "    pixs = pred.size\n",
    "    uniques, counts = np.unique(pred, return_counts=True)\n",
    "#     print(\"Predictions in [{}]:\".format(info))\n",
    "    # colorize prediction\n",
    "    pred_color = colorEncode(pred, colors).astype(np.uint8)\n",
    "\n",
    "    # aggregate images and save\n",
    "    im_vis = np.concatenate((img, pred_color), axis=1)\n",
    "\n",
    "    img_name = info.split('/')[-1]\n",
    "    #:torch.save(scores,os.path.join(cfg.TEST.result, img_name.replace('.jpg', '.pt')))\n",
    "    scores = scores[0,:,:,:]\n",
    "    sem_scores,sem_labels=torch.topk(scores,3,dim=0)\n",
    "    sem_labels = sem_labels.type(torch.FloatTensor)\n",
    "    sem_labels = torch.div(sem_labels,255)\n",
    "    shape = sem_labels.size()\n",
    "    sem_scores = np.transpose(sem_scores.cpu().numpy(),(1,2,0))\n",
    "    sem_labels = np.transpose(sem_labels.cpu().numpy(),(1,2,0))\n",
    "    sem_scores = sem_scores[...,[2,1,0]]\n",
    "    sem_labels = sem_labels[...,[2,1,0]]\n",
    "    Image.fromarray((sem_scores*255).astype(np.uint8)).save(\n",
    "        os.path.join(cfg.TEST.result,'sem_score', img_name.replace('.jpg', '.png')))\n",
    "    Image.fromarray((sem_labels*255).astype(np.uint8)).save(\n",
    "        os.path.join(cfg.TEST.result,'sem_label', img_name.replace('.jpg', '.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(cfg, gpu):\n",
    "    torch.cuda.set_device(gpu)\n",
    "\n",
    "    # Network Builders\n",
    "    net_encoder = ModelBuilder.build_encoder(\n",
    "        arch=cfg.MODEL.arch_encoder,\n",
    "        fc_dim=cfg.MODEL.fc_dim,\n",
    "        weights=cfg.MODEL.weights_encoder)\n",
    "    net_decoder = ModelBuilder.build_decoder(\n",
    "        arch=cfg.MODEL.arch_decoder,\n",
    "        fc_dim=cfg.MODEL.fc_dim,\n",
    "        num_class=cfg.DATASET.num_class,\n",
    "        weights=cfg.MODEL.weights_decoder,\n",
    "        use_softmax=True)\n",
    "\n",
    "    crit = nn.NLLLoss(ignore_index=-1)\n",
    "\n",
    "    segmentation_module = SegmentationModule(net_encoder, net_decoder, crit)\n",
    "\n",
    "    # Dataset and Loader\n",
    "    dataset_test = TestDataset(\n",
    "        cfg.list_test,\n",
    "        cfg.DATASET)\n",
    "    loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test,\n",
    "        batch_size=cfg.TEST.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=user_scattered_collate,\n",
    "        num_workers=5,\n",
    "        drop_last=True)\n",
    "\n",
    "    segmentation_module.cuda()\n",
    "\n",
    "    # Main loop\n",
    "    test(segmentation_module, loader_test, gpu)\n",
    "\n",
    "    print('Inference done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = './semantic-segmentation-pytorch/config/ade20k-resnet50dilated-ppm_deepsup.yaml'\n",
    "cfg.merge_from_file(config_path)\n",
    "\n",
    "cfg.DIR = './semantic-segmentation-pytorch/ckpt/ade20k-resnet50dilated-ppm_deepsup'\n",
    "cfg.TEST.checkpoint = 'epoch_20.pth'\n",
    "cfg.TEST.result = './demo/basketball_01/'\n",
    "\n",
    "cfg.MODEL.arch_encoder = cfg.MODEL.arch_encoder.lower()\n",
    "cfg.MODEL.arch_decoder = cfg.MODEL.arch_decoder.lower()\n",
    "\n",
    "# absolute paths of model weights\n",
    "cfg.MODEL.weights_encoder = os.path.join(\n",
    "    cfg.DIR, 'encoder_' + cfg.TEST.checkpoint)\n",
    "cfg.MODEL.weights_decoder = os.path.join(\n",
    "    cfg.DIR, 'decoder_' + cfg.TEST.checkpoint)\n",
    "\n",
    "assert os.path.exists(cfg.MODEL.weights_encoder) and \\\n",
    "    os.path.exists(cfg.MODEL.weights_decoder), \"checkpoint does not exitst!\"\n",
    "\n",
    "\n",
    "# read data\n",
    "img_path = './demo/basketball_01/raw'\n",
    "if os.path.isdir(img_path):\n",
    "        imgs = find_recursive(img_path)\n",
    "else:\n",
    "        imgs = [img_path]\n",
    "assert len(imgs), \"imgs should be a path to image (.jpg) or directory.\"\n",
    "\n",
    "cfg.list_test = [{'fpath_img': x} for x in imgs]\n",
    "\n",
    "if not os.path.isdir(cfg.TEST.result):\n",
    "    os.makedirs(cfg.TEST.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for net_encoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/90 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for net_decoder\n",
      "# samples: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  1%|          | 1/90 [00:02<03:40,  2.48s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 2/90 [00:04<03:16,  2.24s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 3/90 [00:05<03:01,  2.08s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 4/90 [00:07<02:49,  1.97s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|▌         | 5/90 [00:09<02:42,  1.91s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|▋         | 6/90 [00:11<02:36,  1.86s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 7/90 [00:12<02:31,  1.83s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|▉         | 8/90 [00:14<02:28,  1.81s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 9/90 [00:16<02:23,  1.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|█         | 10/90 [00:18<02:22,  1.78s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|█▏        | 11/90 [00:19<02:20,  1.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█▎        | 12/90 [00:21<02:16,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█▍        | 13/90 [00:23<02:14,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|█▌        | 14/90 [00:24<02:11,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|█▋        | 15/90 [00:26<02:10,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|█▊        | 16/90 [00:28<02:11,  1.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|█▉        | 17/90 [00:30<02:08,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|██        | 18/90 [00:32<02:05,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|██        | 19/90 [00:33<02:02,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|██▏       | 20/90 [00:35<02:00,  1.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|██▎       | 21/90 [00:37<01:59,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|██▍       | 22/90 [00:38<01:57,  1.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██▌       | 23/90 [00:40<01:54,  1.71s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██▋       | 24/90 [00:42<01:53,  1.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██▊       | 25/90 [00:44<01:51,  1.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|██▉       | 26/90 [00:45<01:50,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███       | 27/90 [00:47<01:47,  1.71s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███       | 28/90 [00:49<01:47,  1.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|███▏      | 29/90 [00:50<01:45,  1.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|███▎      | 30/90 [00:52<01:45,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|███▍      | 31/90 [00:54<01:45,  1.78s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|███▌      | 32/90 [00:56<01:45,  1.81s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|███▋      | 33/90 [00:58<01:41,  1.78s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███▊      | 34/90 [00:59<01:38,  1.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|███▉      | 35/90 [01:01<01:37,  1.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 36/90 [01:03<01:35,  1.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|████      | 37/90 [01:05<01:33,  1.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████▏     | 38/90 [01:06<01:30,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████▎     | 39/90 [01:08<01:28,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|████▍     | 40/90 [01:10<01:25,  1.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|████▌     | 41/90 [01:12<01:25,  1.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|████▋     | 42/90 [01:13<01:22,  1.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████▊     | 43/90 [01:15<01:21,  1.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|████▉     | 44/90 [01:17<01:19,  1.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 45/90 [01:18<01:17,  1.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|█████     | 46/90 [01:20<01:15,  1.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|█████▏    | 47/90 [01:22<01:14,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|█████▎    | 48/90 [01:24<01:13,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████▍    | 49/90 [01:25<01:11,  1.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████▌    | 50/90 [01:27<01:09,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████▋    | 51/90 [01:29<01:08,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|█████▊    | 52/90 [01:31<01:06,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|█████▉    | 53/90 [01:32<01:04,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████    | 54/90 [01:34<01:02,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|██████    | 55/90 [01:36<01:00,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|██████▏   | 56/90 [01:38<00:59,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|██████▎   | 57/90 [01:39<00:56,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|██████▍   | 58/90 [01:41<00:55,  1.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|██████▌   | 59/90 [01:43<00:53,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 60/90 [01:44<00:51,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|██████▊   | 61/90 [01:46<00:51,  1.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████▉   | 62/90 [01:48<00:48,  1.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|███████   | 63/90 [01:50<00:47,  1.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████   | 64/90 [01:52<00:45,  1.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████▏  | 65/90 [01:53<00:44,  1.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████▎  | 66/90 [01:55<00:43,  1.82s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|███████▍  | 67/90 [01:57<00:41,  1.81s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|███████▌  | 68/90 [01:59<00:39,  1.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|███████▋  | 69/90 [02:00<00:36,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|███████▊  | 70/90 [02:02<00:35,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|███████▉  | 71/90 [02:04<00:33,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|████████  | 72/90 [02:06<00:31,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|████████  | 73/90 [02:07<00:29,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████▏ | 74/90 [02:09<00:27,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████▎ | 75/90 [02:11<00:26,  1.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████▍ | 76/90 [02:13<00:24,  1.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████▌ | 77/90 [02:14<00:22,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|████████▋ | 78/90 [02:16<00:21,  1.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|████████▊ | 79/90 [02:18<00:19,  1.78s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|████████▉ | 80/90 [02:20<00:17,  1.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|█████████ | 81/90 [02:22<00:16,  1.79s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|█████████ | 82/90 [02:23<00:14,  1.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|█████████▏| 83/90 [02:25<00:12,  1.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 93%|█████████▎| 84/90 [02:27<00:10,  1.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|█████████▍| 85/90 [02:29<00:08,  1.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|█████████▌| 86/90 [02:30<00:07,  1.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|█████████▋| 87/90 [02:32<00:05,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████▊| 88/90 [02:34<00:03,  1.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████▉| 89/90 [02:36<00:01,  1.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 90/90 [02:37<00:00,  1.75s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference done!\n",
      "Runing time: 159.04933881759644\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "main(cfg, 0)\n",
    "time_end = time.time()\n",
    "print('Runing time: {}'.format(time_end - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda (SemanticSceneRegonition)",
   "language": "python",
   "name": "semanticsceneregonition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
